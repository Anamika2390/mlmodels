<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, shrink-to-fit=no, initial-scale=1">
    
    <meta name="author" content="Lexionbear: https://github.com/lexionbear">

    <title>Machine Learning Models</title>
	<meta name="description" content="Collections of state-of-art tensorflow machine learning algorithms and models">
	
    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/simple-sidebar.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>
    <div id="wrapper">

        <!-- Sidebar -->
        <div id="sidebar-wrapper">
            <ul class="sidebar-nav">
                <li class="sidebar-brand">
                    <a href="">
                        Models
                    </a>
                </li>
                <li>
                    <a href="#googlenet">GoogleNet Image Classifier</a>
                </li>
				<li>
                    <a href="#resnet">ResNet Image Classifier</a>
                </li>
				<li>
                    <a href="#vgg16">VGG16 Image Classifier</a>
                </li>
            </ul>
        </div>
        <!-- /#sidebar-wrapper -->

        <!-- Page Content -->
        <div id="page-content-wrapper">
            <div class="container-fluid row">
				<div class="col-md-1"></div>
				<div class="col-md-10">
					<div id="googlenet" class="row">
						<div class="col-lg-12 row">
							<h1>GoogleNet Image Classifier</h1>
							<p class="lead">Publication: <a href="http://arxiv.org/abs/1409.4842">Going Deeper with Convolution</a></p>
							<p>GoogleNet is a cheap and relatively accurate 1000 class image classifier first published in 2014</p>
							<div class="col-lg-8">
								<table class="table table-bordered table-hover table-responsive"> 
									<tbody> 
										<tr> 
											<th scope="row" rowspan="2">Accuracy</th>
											<td>ILSVRC 2014 dataset: Accuracy (Top-5) <b>93.33%</b></td>
										</tr>
										<tr>
											<td>ILSVRC 2012 dataset: Accuracy (Top-5) <b>89.06%</b></td>
										</tr>
										<tr> 
											<th scope="row">Model Size</th>
											<td>27Mb in npy format</td>
										</tr> 
										<tr> 
											<th scope="row">Architecture</th>
											<td>
												<p>9 identical blocks of parallel convolutional neural network layers with downsampling, shown below</p>
												<img src="img/googlenet/googlenet_block.png" class="img-responsive" alt="GoogleNet basic block"/>
											</td>
										</tr>
										<tr> 
											<th scope="row">Advantage</th>
											<td>
												<ul>
													<li>Simplicity: the network consists of 9 identical and relatively simple blocks</li>
													<li>Parallelism: the network layers within each block are structure in 4 parallel pathway</li>
													<li>Computation and memory efficiency: because of the parallel network implementation and the dimension reduction layers in each block, the model size is contained within 27Mb npy file, and its execution time beats VGG or ResNet on commodity hardware.</li>
												</ul>
											</td>
										</tr>
										<tr> 
											<th scope="row">Disadvantage</th>
											<td>
												<ul>
													<li>Lower accuracy: the high efficiency comes at a small cost of the model accuracy on ILSVRC 2012</li>
												</ul>
											</td>
										</tr>
									</tbody>
								</table>
							</div>
							<div class="col-lg-4"></div>
						</div>
						
						<div class="col-lg-12 row">
							<p class="lead">Model code in Tensorflow: <a href="https://lexiondebug.blob.core.windows.net/mlmodel/models/googlenet.py">GoogleNet Code</a></p>
							<p class="lead">Pre-trained model in npy format: <a href="https://lexiondebug.blob.core.windows.net/mlmodel/models/googlenet.npy">GoogleNet Model</a></p>
							<p>Output label lookup dictionary: <a href="https://lexiondebug.blob.core.windows.net/mlmodel/models/imagenet-classes.txt">Imagenet Classes</a></p>
							<p>The model is converted into Tensorflow using ethereon's <code><a href="https://github.com/ethereon/caffe-tensorflow">caffe-tensorflow</a></code> library. The converted network requires the library to initialize network structure.</p>
						</div>
						<hr/>
					</div>
					<div id="resnet" class="row">
						<div class="col-lg-12 row">
							<h1>ResNet50 Image Classifier</h1>
							<p class="lead">Publication: <a href="http://arxiv.org/abs/1512.03385">Deep Residual Learning for Image Recognition</a></p>
							<p>ResNet50 is a highly accurate model published by Microsoft research. It's gain in accuracy comes at a cost of computational expenses. Both its model memory cost and execution time exceed those of GoogleNet.</p>
							<div class="col-lg-8">
								<table class="table table-bordered table-hover table-responsive"> 
									<tbody> 
										<tr> 
											<th scope="row">Accuracy</th>
											<td>ILSVRC 2012 dataset: Accuracy (Top-5) <b>92.02%</b></td>
										</tr> 
										<tr> 
											<th scope="row">Model Size</th>
											<td>100Mb in npy format</td>
										</tr> 
										<tr> 
											<th scope="row">Architecture</th>
											<td>
												<p>50 layers of similar blocks with "bypass connections" shown as the <i>x identity</i> below</p>
												<img src="img/resnet/resnet_block.png" class="img-responsive" alt="GoogleNet basic block"/>
												<p>Shortcut path serves as a model simplifier and provides the benefit of simple models in a complex network. If shortcut path is dominant, the layers between this shortcut are essentially ignored, reducing the complexity of the model in effect.</p>
											</td>
										</tr>
										<tr> 
											<th scope="row">Advantage</th>
											<td>
												<ul>
													<li>High accuracy: ResNet achieves one of the best performance accuracy, beating VGG and GoogleNet in ILSVRC 2012 testset</li>
												</ul>
											</td>
										</tr>
										<tr> 
											<th scope="row">Disadvantage</th>
											<td>
												<ul>
													<li>Relative complex model: although simple in concept, ResNet implementation is highly complicated due to the extensive use of shortcut path that skips layers and pooling, normalizations operations. This increases debugging and innovation cost.</li>
												</ul>
											</td>
										</tr>
									</tbody>
								</table>
							</div>
							<div class="col-lg-4"></div>
						</div>
						<div class="col-lg-12 row">
							<p class="lead">Model code in Tensorflow: <a href="https://lexiondebug.blob.core.windows.net/mlmodel/models/resnet.py">ResNet Code</a></p>
							<p class="lead">Pre-trained model in npy format: <a href="https://lexiondebug.blob.core.windows.net/mlmodel/models/res50.npy">ResNet Model</a></p>
							<p>Output label lookup dictionary: <a href="https://lexiondebug.blob.core.windows.net/mlmodel/models/imagenet-classes.txt">Imagenet Classes</a></p>
							<p>The model is converted into Tensorflow using ethereon's <code><a href="https://github.com/ethereon/caffe-tensorflow">caffe-tensorflow</a></code> library. The converted network requires the library to initialize network structure.</p>
						</div>
						<hr/>
					</div>	
					<div id="vgg16" class="row">
						<div class="col-lg-12 row">
							<h1>VGG16 Image Classifier</h1>
							<p class="lead">Publication: <a href="http://arxiv.org/abs/1409.1556">Very Deep Convolutional Networks for Large-Scale Image Recognition</a></p>
							<p>VGG is published by researchers at University of Oxford. The highlight is its simplicity in architecture. Majority of the network consists of convolution layers and dropout layers in simple cascading fashion.</p>
							<div class="col-lg-8">
								<table class="table table-bordered table-hover table-responsive"> 
									<tbody> 
										<tr> 
											<th scope="row">Accuracy</th>
											<td>ILSVRC 2012 dataset: Accuracy (Top-5) <b>89.88%</b></td>
										</tr> 
										<tr> 
											<th scope="row">Model Size</th>
											<td>540Mb in npy format</td>
										</tr> 
										<tr> 
											<th scope="row">Architecture</th>
											<td>
												<ul>
													<li>As the name suggests, VGG16 consists of 16 layers. Several variation exists. It repeats the pattern of 2 convolution layers followed by 1 dropout layers until the fully connected layer at the end.</li>
													<li>Its design follows the philosophy of conserving time complexity, where each time max pooling reduce the input dimension by 2, number of kernals in the next convolutional layer increases by 2</li>
												</ul>
											</td>
										</tr>
										<tr> 
											<th scope="row">Advantage</th>
											<td>
												<ul>
													<li>Simplicity: majority of the network consists of convolution layers and dropout layers in simple cascading fashion. It has no shortcut, normalization or concatenations operations.</li>
												</ul>
											</td>
										</tr>
										<tr> 
											<th scope="row">Disadvantage</th>
											<td>
												<ul>
													<li>High memory and computational cost: although it is simple in network architecture, the exponential increase of convolutional kernals lead to significant increase of its model size as well as model execution time, comparing with GoogleNet and ResNet</li>
												</ul>
											</td>
										</tr>
									</tbody>
								</table>
							</div>
							<div class="col-lg-4"></div>
						</div>
						<div class="col-lg-12 row">
							<p class="lead">Model code in Tensorflow: <a href="https://lexiondebug.blob.core.windows.net/mlmodel/models/vgg.py">VGG16 Code</a></p>
							<p class="lead">Pre-trained model in npy format: <a href="https://lexiondebug.blob.core.windows.net/mlmodel/models/VGG_16.npy">VGG16 Model <b>(540Mb)</b></a></p>
							<p>Output label lookup dictionary: <a href="https://lexiondebug.blob.core.windows.net/mlmodel/models/imagenet-classes.txt">Imagenet Classes</a></p>
							<p>The model is converted into Tensorflow using ethereon's <code><a href="https://github.com/ethereon/caffe-tensorflow">caffe-tensorflow</a></code> library. The converted network requires the library to initialize network structure.</p>
						</div>
						<hr/>
					</div>	
				</div>
				<div class="col-md-1"></div>
			</div>
        
			<div class="container footer">
				<hr/>

				<!-- Footer -->
				<footer>
					<div class="row">
						<div class="col-sm-6 col-lg-12">
							<p>Want to report inaccurate data or contribute to the model documentation on the site? Find us on <a href="https://github.com/lexionbear/mlmodels/tree/master">Github</a></p>
							<!--<p>Copyright &copy; lexionbear.github.io 2016</p>-->
						</div>
					</div>
				</footer>

			</div>
		</div>
        <!-- /#page-content-wrapper -->

    </div>
    <!-- /#wrapper -->
	
    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Custom Script -->
    <script>

    </script>
	
</body>

</html>
